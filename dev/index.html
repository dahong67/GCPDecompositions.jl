<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home Â· GCPDecompositions.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://dahong67.github.io/GCPDecompositions.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>GCPDecompositions.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Docstrings"><span>Docstrings</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dahong67/GCPDecompositions.jl/blob/master/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="GCPDecompositions:-Generalized-CP-Decompositions"><a class="docs-heading-anchor" href="#GCPDecompositions:-Generalized-CP-Decompositions">GCPDecompositions: Generalized CP Decompositions</a><a id="GCPDecompositions:-Generalized-CP-Decompositions-1"></a><a class="docs-heading-anchor-permalink" href="#GCPDecompositions:-Generalized-CP-Decompositions" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/dahong67/GCPDecompositions.jl">GCPDecompositions</a>.</p><blockquote><p>ðŸ‘‹ <em>This package provides research code and work is ongoing. If you are interested in using it in your own research, <strong>I&#39;d love to hear from you and collaborate!</strong> Feel free to write: <a href="mailto:hong@udel.edu">hong@udel.edu</a></em></p></blockquote><p>Please cite the following papers for this technique:</p><blockquote><p>David Hong, Tamara G. Kolda, Jed A. Duersch. &quot;Generalized Canonical Polyadic Tensor Decomposition&quot;, <em>SIAM Review</em> 62:133-163, 2020. <a href="https://doi.org/10.1137/18M1203626">https://doi.org/10.1137/18M1203626</a> <a href="https://arxiv.org/abs/1808.07452">https://arxiv.org/abs/1808.07452</a></p><p>Tamara G. Kolda, David Hong. &quot;Stochastic Gradients for Large-Scale Tensor Decomposition&quot;, <em>SIAM Journal on Mathematics of Data Science</em> 2:1066-1095, 2020. <a href="https://doi.org/10.1137/19M1266265">https://doi.org/10.1137/19M1266265</a> <a href="https://arxiv.org/abs/1906.01687">https://arxiv.org/abs/1906.01687</a></p></blockquote><p>In BibTeX form:</p><pre><code class="language-bibtex hljs">@Article{hkd2020gcp,
  title =        &quot;Generalized Canonical Polyadic Tensor Decomposition&quot;,
  author =       &quot;David Hong and Tamara G. Kolda and Jed A. Duersch&quot;,
  journal =      &quot;{SIAM} Review&quot;,
  year =         &quot;2020&quot;,
  volume =       &quot;62&quot;,
  number =       &quot;1&quot;,
  pages =        &quot;133--163&quot;,
  DOI =          &quot;10.1137/18M1203626&quot;,
}

@Article{kh2020sgf,
  title =        &quot;Stochastic Gradients for Large-Scale Tensor Decomposition&quot;,
  author =       &quot;Tamara G. Kolda and David Hong&quot;,
  journal =      &quot;{SIAM} Journal on Mathematics of Data Science&quot;,
  year =         &quot;2020&quot;,
  volume =       &quot;2&quot;,
  number =       &quot;4&quot;,
  pages =        &quot;1066--1095&quot;,
  DOI =          &quot;10.1137/19M1266265&quot;,
}</code></pre><h2 id="Docstrings"><a class="docs-heading-anchor" href="#Docstrings">Docstrings</a><a id="Docstrings-1"></a><a class="docs-heading-anchor-permalink" href="#Docstrings" title="Permalink"></a></h2><ul><li><a href="#GCPDecompositions.GCPDecompositions"><code>GCPDecompositions.GCPDecompositions</code></a></li><li><a href="#GCPDecompositions.AbstractLoss"><code>GCPDecompositions.AbstractLoss</code></a></li><li><a href="#GCPDecompositions.BernoulliLogitLoss"><code>GCPDecompositions.BernoulliLogitLoss</code></a></li><li><a href="#GCPDecompositions.BernoulliOddsLoss"><code>GCPDecompositions.BernoulliOddsLoss</code></a></li><li><a href="#GCPDecompositions.BetaDivergenceLoss"><code>GCPDecompositions.BetaDivergenceLoss</code></a></li><li><a href="#GCPDecompositions.CPD"><code>GCPDecompositions.CPD</code></a></li><li><a href="#GCPDecompositions.GammaLoss"><code>GCPDecompositions.GammaLoss</code></a></li><li><a href="#GCPDecompositions.HuberLoss"><code>GCPDecompositions.HuberLoss</code></a></li><li><a href="#GCPDecompositions.LeastSquaresLoss"><code>GCPDecompositions.LeastSquaresLoss</code></a></li><li><a href="#GCPDecompositions.NegativeBinomialOddsLoss"><code>GCPDecompositions.NegativeBinomialOddsLoss</code></a></li><li><a href="#GCPDecompositions.NonnegativeLeastSquaresLoss"><code>GCPDecompositions.NonnegativeLeastSquaresLoss</code></a></li><li><a href="#GCPDecompositions.PoissonLogLoss"><code>GCPDecompositions.PoissonLogLoss</code></a></li><li><a href="#GCPDecompositions.PoissonLoss"><code>GCPDecompositions.PoissonLoss</code></a></li><li><a href="#GCPDecompositions.RayleighLoss"><code>GCPDecompositions.RayleighLoss</code></a></li><li><a href="#GCPDecompositions.UserDefinedLoss"><code>GCPDecompositions.UserDefinedLoss</code></a></li><li><a href="#GCPDecompositions._checked_khatrirao_dims-Union{Tuple{Vararg{T, N}}, Tuple{N}, Tuple{T}} where {T&lt;:(AbstractMatrix{T} where T), N}"><code>GCPDecompositions._checked_khatrirao_dims</code></a></li><li><a href="#GCPDecompositions._checked_mttkrp_dims-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions._checked_mttkrp_dims</code></a></li><li><a href="#GCPDecompositions.create_mttkrp_buffer-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions.create_mttkrp_buffer</code></a></li><li><a href="#GCPDecompositions.gcp"><code>GCPDecompositions.gcp</code></a></li><li><a href="#GCPDecompositions.khatrirao-Union{Tuple{Vararg{T, N}}, Tuple{N}, Tuple{T}} where {T&lt;:(AbstractMatrix{T} where T), N}"><code>GCPDecompositions.khatrirao</code></a></li><li><a href="#GCPDecompositions.khatrirao!-Union{Tuple{N}, Tuple{T}, Tuple{T, Vararg{T, N}}} where {T&lt;:(AbstractMatrix{T} where T), N}"><code>GCPDecompositions.khatrirao!</code></a></li><li><a href="#GCPDecompositions.mttkrp-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions.mttkrp</code></a></li><li><a href="#GCPDecompositions.mttkrp!-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{TM, AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}, Tuple{TM, AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer, Any}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions.mttkrp!</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.GCPDecompositions" href="#GCPDecompositions.GCPDecompositions"><code>GCPDecompositions.GCPDecompositions</code></a> â€” <span class="docstring-category">Module</span></header><section><div><p>Generalized CP Decomposition module. Provides approximate CP tensor decomposition with respect to general losses.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/GCPDecompositions.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.AbstractLoss" href="#GCPDecompositions.AbstractLoss"><code>GCPDecompositions.AbstractLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AbstractLoss</code></pre><p>Abstract type for GCP loss functions <span>$f(x,m)$</span>, where <span>$x$</span> is the data entry and <span>$m$</span> is the model entry.</p><p>Concrete types <code>ConcreteLoss &lt;: AbstractLoss</code> should implement:</p><ul><li><code>value(loss::ConcreteLoss, x, m)</code> that computes the value of the loss function <span>$f(x,m)$</span></li><li><code>deriv(loss::ConcreteLoss, x, m)</code> that computes the value of the partial derivative <span>$\partial_m f(x,m)$</span> with respect to <span>$m$</span></li><li><code>domain(loss::ConcreteLoss)</code> that returns an <code>Interval</code> from IntervalSets.jl defining the domain for <span>$m$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L5-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.BernoulliLogitLoss" href="#GCPDecompositions.BernoulliLogitLoss"><code>GCPDecompositions.BernoulliLogitLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BernoulliLogitLoss(eps::Real = 1e-10)</code></pre><p>Loss corresponding to the statistical assumption of Bernouli data <code>X</code> with log odds-success rate given by the low-rank model tensor <code>M</code></p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \operatorname{Bernouli}(\rho_i)$</span></li><li><strong>Link function:</strong> <span>$m_i = \log(\frac{\rho_i}{1 - \rho_i})$</span></li><li><strong>Loss function:</strong> <span>$f(x, m) = \log(1 + e^m) - xm$</span></li><li><strong>Domain:</strong> <span>$m \in \mathbb{R}$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L160-L170">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.BernoulliOddsLoss" href="#GCPDecompositions.BernoulliOddsLoss"><code>GCPDecompositions.BernoulliOddsLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BernoulliOddsLoss(eps::Real = 1e-10)</code></pre><p>Loss corresponding to the statistical assumption of Bernouli data <code>X</code> with odds-sucess rate given by the low-rank model tensor <code>M</code></p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \operatorname{Bernouli}(\rho_i)$</span></li><li><strong>Link function:</strong> <span>$m_i = \frac{\rho_i}{1 - \rho_i}$</span></li><li><strong>Loss function:</strong> <span>$f(x, m) = \log(m + 1) - x\log(m + \epsilon)$</span></li><li><strong>Domain:</strong> <span>$m \in [0, \infty)$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L137-L147">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.BetaDivergenceLoss" href="#GCPDecompositions.BetaDivergenceLoss"><code>GCPDecompositions.BetaDivergenceLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BetaDivergenceLoss(Î²::Real, eps::Real)

BetaDivergence Loss for given Î²</code></pre><ul><li><strong>Loss function:</strong> <span>$f(x, m; Î²) = \frac{1}{\beta}m^{\beta} - \frac{1}{\beta - 1}xm^{\beta - 1}                       if \beta \in \mathbb{R}  \{0, 1\},                         m - x\log(m) if \beta = 1,                         \frac{x}{m} + \log(m) if \beta = 0$</span></li><li><strong>Domain:</strong> <span>$m \in [0, \infty)$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L231-L241">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.CPD" href="#GCPDecompositions.CPD"><code>GCPDecompositions.CPD</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CPD</code></pre><p>Tensor decomposition type for the canonical polyadic decompositions (CPD) of a tensor (i.e., a multi-dimensional array) <code>A</code>. This is the return type of <code>gcp(_)</code>, the corresponding tensor decomposition function.</p><p>If <code>M::CPD</code> is the decomposition object, the weights <code>Î»</code> and the factor matrices <code>U = (U[1],...,U[N])</code> can be obtained via <code>M.Î»</code> and <code>M.U</code>, such that <code>A = Î£_j Î»[j] U[1][:,j] âˆ˜ â‹¯ âˆ˜ U[N][:,j]</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-cpd.jl#L3-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.GammaLoss" href="#GCPDecompositions.GammaLoss"><code>GCPDecompositions.GammaLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GammaLoss(eps::Real = 1e-10)</code></pre><p>Loss corresponding to a statistical assumption of Gamma-distributed data <code>X</code> with scale given by the low-rank model tensor <code>M</code>.</p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \operatorname{Gamma}(k, \sigma_i)$</span></li><li><strong>Link function:</strong> <span>$m_i = k \sigma_i$</span></li><li><strong>Loss function:</strong> <span>$f(x,m) = \frac{x}{m + \epsilon} + \log(m + \epsilon)$</span></li><li><strong>Domain:</strong> <span>$m \in [0, \infty)$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L93-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.HuberLoss" href="#GCPDecompositions.HuberLoss"><code>GCPDecompositions.HuberLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">HuberLoss(Î”::Real)</code></pre><p>Huber Loss for given Î”</p><ul><li><strong>Loss function:</strong> <span>$f(x, m) = (x - m)^2 if \abs(x - m)\leq\Delta, 2\Delta\abs(x - m) - \Delta^2 otherwise$</span></li><li><strong>Domain:</strong> <span>$m \in \mathbb{R}$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L211-L218">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.LeastSquaresLoss" href="#GCPDecompositions.LeastSquaresLoss"><code>GCPDecompositions.LeastSquaresLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LeastSquaresLoss()</code></pre><p>Loss corresponding to conventional CP decomposition. Corresponds to a statistical assumption of Gaussian data <code>X</code> with mean given by the low-rank model tensor <code>M</code>.</p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \mathcal{N}(\mu_i, \sigma)$</span></li><li><strong>Link function:</strong> <span>$m_i = \mu_i$</span></li><li><strong>Loss function:</strong> <span>$f(x,m) = (x-m)^2$</span></li><li><strong>Domain:</strong> <span>$m \in \mathbb{R}$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L21-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.NegativeBinomialOddsLoss" href="#GCPDecompositions.NegativeBinomialOddsLoss"><code>GCPDecompositions.NegativeBinomialOddsLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NegativeBinomialOddsLoss(r::Integer, eps::Real = 1e-10)</code></pre><p>Loss corresponding to the statistical assumption of Negative Binomial data <code>X</code> with log odds failure rate given by the low-rank model tensor <code>M</code></p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \operatorname{NegativeBinomial}(r, \rho_i)$</span></li><li><strong>Link function:</strong> <span>$m = \frac{\rho}{1 - \rho}$</span></li><li><strong>Loss function:</strong> <span>$f(x, m) = (r + x) \log(1 + m) - x\log(m + \epsilon)$</span></li><li><strong>Domain:</strong> <span>$m \in [0, \infty)$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L183-L193">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.NonnegativeLeastSquaresLoss" href="#GCPDecompositions.NonnegativeLeastSquaresLoss"><code>GCPDecompositions.NonnegativeLeastSquaresLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NonnegativeLeastSquaresLoss()</code></pre><p>Loss corresponding to nonnegative CP decomposition. Corresponds to a statistical assumption of Gaussian data <code>X</code> with nonnegative mean given by the low-rank model tensor <code>M</code>.</p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \mathcal{N}(\mu_i, \sigma)$</span></li><li><strong>Link function:</strong> <span>$m_i = \mu_i$</span></li><li><strong>Loss function:</strong> <span>$f(x,m) = (x-m)^2$</span></li><li><strong>Domain:</strong> <span>$m \in [0, \infty)$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L38-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.PoissonLogLoss" href="#GCPDecompositions.PoissonLogLoss"><code>GCPDecompositions.PoissonLogLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PoissonLogLoss()</code></pre><p>Loss corresponding to a statistical assumption of Poisson data <code>X</code> with log-rate given by the low-rank model tensor <code>M</code>.</p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \operatorname{Poisson}(\lambda_i)$</span></li><li><strong>Link function:</strong> <span>$m_i = \log \lambda_i$</span></li><li><strong>Loss function:</strong> <span>$f(x,m) = e^m - x m$</span></li><li><strong>Domain:</strong> <span>$m \in \mathbb{R}$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L77-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.PoissonLoss" href="#GCPDecompositions.PoissonLoss"><code>GCPDecompositions.PoissonLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PoissonLoss(eps::Real = 1e-10)</code></pre><p>Loss corresponding to a statistical assumption of Poisson data <code>X</code> with rate given by the low-rank model tensor <code>M</code>.</p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \operatorname{Poisson}(\lambda_i)$</span></li><li><strong>Link function:</strong> <span>$m_i = \lambda_i$</span></li><li><strong>Loss function:</strong> <span>$f(x,m) = m - x \log(m + \epsilon)$</span></li><li><strong>Domain:</strong> <span>$m \in [0, \infty)$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L55-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.RayleighLoss" href="#GCPDecompositions.RayleighLoss"><code>GCPDecompositions.RayleighLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RayleighLoss(eps::Real = 1e-10)</code></pre><p>Loss corresponding to the statistical assumption of Rayleigh data <code>X</code> with sacle given by the low-rank model tensor <code>M</code></p><ul><li><strong>Distribution:</strong> <span>$x_i \sim \operatorname{Rayleigh}(\theta_i)$</span></li><li><strong>Link function:</strong> <span>$m_i = \sqrt{\frac{\pi}{2}\theta_i}$</span></li><li><strong>Loss function:</strong> <span>$f(x, m) = 2\log(m + \epsilon) + \frac{\pi}{4}(\frac{x}{m + \epsilon})^2$</span></li><li><strong>Domain:</strong> <span>$m \in [0, \infty)$</span></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L115-L125">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.UserDefinedLoss" href="#GCPDecompositions.UserDefinedLoss"><code>GCPDecompositions.UserDefinedLoss</code></a> â€” <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">UserDefinedLoss</code></pre><p>Type for user-defined loss functions <span>$f(x,m)$</span>, where <span>$x$</span> is the data entry and <span>$m$</span> is the model entry.</p><p>Contains three fields:</p><ol><li><code>func::Function</code>   : function that evaluates the loss function <span>$f(x,m)$</span></li><li><code>deriv::Function</code>  : function that evaluates the partial derivative <span>$\partial_m f(x,m)$</span> with respect to <span>$m$</span></li><li><code>domain::Interval</code> : <code>Interval</code> from IntervalSets.jl defining the domain for <span>$m$</span></li></ol><p>The constructor is <code>UserDefinedLoss(func; deriv, domain)</code>. If not provided,</p><ul><li><code>deriv</code> is automatically computed from <code>func</code> using forward-mode automatic differentiation</li><li><code>domain</code> gets a default value of <code>Interval(-Inf, +Inf)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/type-losses.jl#L272-L289">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions._checked_khatrirao_dims-Union{Tuple{Vararg{T, N}}, Tuple{N}, Tuple{T}} where {T&lt;:(AbstractMatrix{T} where T), N}" href="#GCPDecompositions._checked_khatrirao_dims-Union{Tuple{Vararg{T, N}}, Tuple{N}, Tuple{T}} where {T&lt;:(AbstractMatrix{T} where T), N}"><code>GCPDecompositions._checked_khatrirao_dims</code></a> â€” <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">_checked_khatrirao_dims(A1, A2, ...)</code></pre><p>Check that <code>A1</code>, <code>A2</code>, etc. have compatible dimensions for the Khatri-Rao product. If so, return a tuple of the number of rows and the shared number of columns. If not, throw an error.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/kernels.jl#L202-L208">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions._checked_mttkrp_dims-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}" href="#GCPDecompositions._checked_mttkrp_dims-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions._checked_mttkrp_dims</code></a> â€” <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">_checked_mttkrp_dims(X, (U1, U2, ..., UN), n)</code></pre><p>Check that <code>X</code> and <code>U</code> have compatible dimensions for the mode-<code>n</code> MTTKRP. If so, return a tuple of the number of rows and the shared number of columns for the Khatri-Rao product. If not, throw an error.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/kernels.jl#L135-L141">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.create_mttkrp_buffer-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}" href="#GCPDecompositions.create_mttkrp_buffer-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions.create_mttkrp_buffer</code></a> â€” <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">create_mttkrp_buffer(X, U, n)</code></pre><p>Create buffer to hold intermediate calculations in <code>mttkrp!</code>.</p><p>Always use <code>create_mttkrp_buffer</code> to make a <code>buffer</code> for <code>mttkrp!</code>; the internal details of <code>buffer</code> may change in the future and should not be relied upon.</p><p>See also: <code>mttkrp!</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/kernels.jl#L107-L117">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.gcp" href="#GCPDecompositions.gcp"><code>GCPDecompositions.gcp</code></a> â€” <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">gcp(X::Array, r, loss = LeastSquaresLoss();
    constraints = default_constraints(loss),
    algorithm = default_algorithm(X, r, loss, constraints)) -&gt; CPD</code></pre><p>Compute an approximate rank-<code>r</code> CP decomposition of the tensor <code>X</code> with respect to the loss function <code>loss</code> and return a <code>CPD</code> object.</p><p>Keyword arguments:</p><ul><li><code>constraints</code> : a <code>Tuple</code> of constraints on the factor matrices <code>U = (U[1],...,U[N])</code>.</li><li><code>algorithm</code>   : algorithm to use</li></ul><p>Conventional CP corresponds to the default <code>LeastSquaresLoss()</code> loss with the default of no constraints (i.e., <code>constraints = ()</code>).</p><p>If the LossFunctions.jl package is also loaded, <code>loss</code> can also be a loss function from that package. Check <code>GCPDecompositions.LossFunctionsExt.SupportedLosses</code> to see what losses are supported.</p><p>See also: <code>CPD</code>, <code>AbstractLoss</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/gcp-opt.jl#L4-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.khatrirao!-Union{Tuple{N}, Tuple{T}, Tuple{T, Vararg{T, N}}} where {T&lt;:(AbstractMatrix{T} where T), N}" href="#GCPDecompositions.khatrirao!-Union{Tuple{N}, Tuple{T}, Tuple{T, Vararg{T, N}}} where {T&lt;:(AbstractMatrix{T} where T), N}"><code>GCPDecompositions.khatrirao!</code></a> â€” <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">khatrirao!(K, A1, A2, ...)</code></pre><p>Compute the Khatri-Rao product (i.e., the column-wise Kronecker product) of the matrices <code>A1</code>, <code>A2</code>, etc. and store the result in <code>K</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/kernels.jl#L172-L177">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.khatrirao-Union{Tuple{Vararg{T, N}}, Tuple{N}, Tuple{T}} where {T&lt;:(AbstractMatrix{T} where T), N}" href="#GCPDecompositions.khatrirao-Union{Tuple{Vararg{T, N}}, Tuple{N}, Tuple{T}} where {T&lt;:(AbstractMatrix{T} where T), N}"><code>GCPDecompositions.khatrirao</code></a> â€” <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">khatrirao(A1, A2, ...)</code></pre><p>Compute the Khatri-Rao product (i.e., the column-wise Kronecker product) of the matrices <code>A1</code>, <code>A2</code>, etc.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/kernels.jl#L161-L166">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.mttkrp!-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{TM, AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}, Tuple{TM, AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer, Any}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}" href="#GCPDecompositions.mttkrp!-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{TM, AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}, Tuple{TM, AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer, Any}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions.mttkrp!</code></a> â€” <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mttkrp!(G, X, (U1, U2, ..., UN), n, buffer=create_mttkrp_buffer(X, U, n))</code></pre><p>Compute the Matricized Tensor Times Khatri-Rao Product (MTTKRP) of an N-way tensor X with the matrices U1, U2, ..., UN along mode n and store the result in G.</p><p>Optionally, provide a <code>buffer</code> for intermediate calculations. Always use <code>create_mttkrp_buffer</code> to make the <code>buffer</code>; the internal details of <code>buffer</code> may change in the future and should not be relied upon.</p><p>Algorithm is based on Section III-B of the paper:</p><blockquote><p><strong>Fast Alternating LS Algorithms for High Order   CANDECOMP/PARAFAC Tensor Factorizations</strong>. Anh-Huy Phan, Petr TichavskÃ½, Andrzej Cichocki. <em>IEEE Transactions on Signal Processing</em>, 2013. DOI: 10.1109/TSP.2013.2269903</p></blockquote><p>See also: <code>mttkrp</code>, <code>create_mttkrp_buffer</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/kernels.jl#L20-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GCPDecompositions.mttkrp-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}" href="#GCPDecompositions.mttkrp-Union{Tuple{N}, Tuple{T}, Tuple{TM}, Tuple{AbstractArray{T, N}, Tuple{Vararg{TM, N}}, Integer}} where {TM&lt;:(AbstractMatrix{T} where T), T, N}"><code>GCPDecompositions.mttkrp</code></a> â€” <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">mttkrp(X, (U1, U2, ..., UN), n)</code></pre><p>Compute the Matricized Tensor Times Khatri-Rao Product (MTTKRP) of an N-way tensor X with the matrices U1, U2, ..., UN along mode n.</p><p>See also: <code>mttkrp!</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dahong67/GCPDecompositions.jl/blob/2a4a0324821ed1961a1b508a890ed0c587187f57/src/kernels.jl#L3-L10">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Tuesday 5 March 2024 04:02">Tuesday 5 March 2024</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
