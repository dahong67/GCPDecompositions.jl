var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = GCPDecompositions","category":"page"},{"location":"#GCPDecompositions:-Generalized-CP-Decompositions","page":"Home","title":"GCPDecompositions: Generalized CP Decompositions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for GCPDecompositions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ðŸ‘‹ This package provides research code and work is ongoing. If you are interested in using it in your own research, I'd love to hear from you and collaborate! Feel free to write: hong@udel.edu","category":"page"},{"location":"","page":"Home","title":"Home","text":"Please cite the following papers for this technique:","category":"page"},{"location":"","page":"Home","title":"Home","text":"David Hong, Tamara G. Kolda, Jed A. Duersch. \"Generalized Canonical Polyadic Tensor Decomposition\", SIAM Review 62:133-163, 2020. https://doi.org/10.1137/18M1203626 https://arxiv.org/abs/1808.07452Tamara G. Kolda, David Hong. \"Stochastic Gradients for Large-Scale Tensor Decomposition\", SIAM Journal on Mathematics of Data Science 2:1066-1095, 2020. https://doi.org/10.1137/19M1266265 https://arxiv.org/abs/1906.01687","category":"page"},{"location":"","page":"Home","title":"Home","text":"In BibTeX form:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@Article{hkd2020gcp,\n  title =        \"Generalized Canonical Polyadic Tensor Decomposition\",\n  author =       \"David Hong and Tamara G. Kolda and Jed A. Duersch\",\n  journal =      \"{SIAM} Review\",\n  year =         \"2020\",\n  volume =       \"62\",\n  number =       \"1\",\n  pages =        \"133--163\",\n  DOI =          \"10.1137/18M1203626\",\n}\n\n@Article{kh2020sgf,\n  title =        \"Stochastic Gradients for Large-Scale Tensor Decomposition\",\n  author =       \"Tamara G. Kolda and David Hong\",\n  journal =      \"{SIAM} Journal on Mathematics of Data Science\",\n  year =         \"2020\",\n  volume =       \"2\",\n  number =       \"4\",\n  pages =        \"1066--1095\",\n  DOI =          \"10.1137/19M1266265\",\n}","category":"page"},{"location":"#Docstrings","page":"Home","title":"Docstrings","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [GCPDecompositions]\nFilter = t -> t !== ncomponents","category":"page"},{"location":"#GCPDecompositions.GCPDecompositions","page":"Home","title":"GCPDecompositions.GCPDecompositions","text":"Generalized CP Decomposition module. Provides approximate CP tensor decomposition with respect to general losses.\n\n\n\n\n\n","category":"module"},{"location":"#GCPDecompositions.AbstractLoss","page":"Home","title":"GCPDecompositions.AbstractLoss","text":"AbstractLoss\n\nAbstract type for GCP loss functions f(xm), where x is the data entry and m is the model entry.\n\nConcrete types ConcreteLoss <: AbstractLoss should implement:\n\nvalue(loss::ConcreteLoss, x, m) that computes the value of the loss function f(xm)\nderiv(loss::ConcreteLoss, x, m) that computes the value of the partial derivative partial_m f(xm) with respect to m\ndomain(loss::ConcreteLoss) that returns an Interval from IntervalSets.jl defining the domain for m\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.BernoulliLogitLoss","page":"Home","title":"GCPDecompositions.BernoulliLogitLoss","text":"BernoulliLogitLoss(eps::Real = 1e-10)\n\nLoss corresponding to the statistical assumption of Bernouli data X with log odds-success rate given by the low-rank model tensor M\n\nDistribution: x_i sim operatornameBernouli(rho_i)\nLink function: m_i = log(fracrho_i1 - rho_i)\nLoss function: f(x m) = log(1 + e^m) - xm\nDomain: m in mathbbR\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.BernoulliOddsLoss","page":"Home","title":"GCPDecompositions.BernoulliOddsLoss","text":"BernoulliOddsLoss(eps::Real = 1e-10)\n\nLoss corresponding to the statistical assumption of Bernouli data X with odds-sucess rate given by the low-rank model tensor M\n\nDistribution: x_i sim operatornameBernouli(rho_i)\nLink function: m_i = fracrho_i1 - rho_i\nLoss function: f(x m) = log(m + 1) - xlog(m + epsilon)\nDomain: m in 0 infty)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.BetaDivergenceLoss","page":"Home","title":"GCPDecompositions.BetaDivergenceLoss","text":"BetaDivergenceLoss(Î²::Real, eps::Real)\n\nBetaDivergence Loss for given Î²\n\nLoss function: f(x m Î²) = frac1betam^beta - frac1beta - 1xm^beta - 1                       if beta in mathbbR  0 1                         m - xlog(m) if beta = 1                         fracxm + log(m) if beta = 0\nDomain: m in 0 infty)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.CPD","page":"Home","title":"GCPDecompositions.CPD","text":"CPD\n\nTensor decomposition type for the canonical polyadic decompositions (CPD) of a tensor (i.e., a multi-dimensional array) A. This is the return type of gcp(_), the corresponding tensor decomposition function.\n\nIf M::CPD is the decomposition object, the weights Î» and the factor matrices U = (U[1],...,U[N]) can be obtained via M.Î» and M.U, such that A = Î£_j Î»[j] U[1][:,j] âˆ˜ â‹¯ âˆ˜ U[N][:,j].\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.GammaLoss","page":"Home","title":"GCPDecompositions.GammaLoss","text":"GammaLoss(eps::Real = 1e-10)\n\nLoss corresponding to a statistical assumption of Gamma-distributed data X with scale given by the low-rank model tensor M.\n\nDistribution: x_i sim operatornameGamma(k sigma_i)\nLink function: m_i = k sigma_i\nLoss function: f(xm) = fracxm + epsilon + log(m + epsilon)\nDomain: m in 0 infty)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.HuberLoss","page":"Home","title":"GCPDecompositions.HuberLoss","text":"HuberLoss(Î”::Real)\n\nHuber Loss for given Î”\n\nLoss function: f(x m) = (x - m)^2 if abs(x - m)leqDelta 2Deltaabs(x - m) - Delta^2 otherwise\nDomain: m in mathbbR\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.LeastSquaresLoss","page":"Home","title":"GCPDecompositions.LeastSquaresLoss","text":"LeastSquaresLoss()\n\nLoss corresponding to conventional CP decomposition. Corresponds to a statistical assumption of Gaussian data X with mean given by the low-rank model tensor M.\n\nDistribution: x_i sim mathcalN(mu_i sigma)\nLink function: m_i = mu_i\nLoss function: f(xm) = (x-m)^2\nDomain: m in mathbbR\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.NegativeBinomialOddsLoss","page":"Home","title":"GCPDecompositions.NegativeBinomialOddsLoss","text":"NegativeBinomialOddsLoss(r::Integer, eps::Real = 1e-10)\n\nLoss corresponding to the statistical assumption of Negative Binomial data X with log odds failure rate given by the low-rank model tensor M\n\nDistribution: x_i sim operatornameNegativeBinomial(r rho_i)\nLink function: m = fracrho1 - rho\nLoss function: f(x m) = (r + x) log(1 + m) - xlog(m + epsilon)\nDomain: m in 0 infty)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.NonnegativeLeastSquaresLoss","page":"Home","title":"GCPDecompositions.NonnegativeLeastSquaresLoss","text":"NonnegativeLeastSquaresLoss()\n\nLoss corresponding to nonnegative CP decomposition. Corresponds to a statistical assumption of Gaussian data X with nonnegative mean given by the low-rank model tensor M.\n\nDistribution: x_i sim mathcalN(mu_i sigma)\nLink function: m_i = mu_i\nLoss function: f(xm) = (x-m)^2\nDomain: m in 0 infty)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.PoissonLogLoss","page":"Home","title":"GCPDecompositions.PoissonLogLoss","text":"PoissonLogLoss()\n\nLoss corresponding to a statistical assumption of Poisson data X with log-rate given by the low-rank model tensor M.\n\nDistribution: x_i sim operatornamePoisson(lambda_i)\nLink function: m_i = log lambda_i\nLoss function: f(xm) = e^m - x m\nDomain: m in mathbbR\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.PoissonLoss","page":"Home","title":"GCPDecompositions.PoissonLoss","text":"PoissonLoss(eps::Real = 1e-10)\n\nLoss corresponding to a statistical assumption of Poisson data X with rate given by the low-rank model tensor M.\n\nDistribution: x_i sim operatornamePoisson(lambda_i)\nLink function: m_i = lambda_i\nLoss function: f(xm) = m - x log(m + epsilon)\nDomain: m in 0 infty)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.RayleighLoss","page":"Home","title":"GCPDecompositions.RayleighLoss","text":"RayleighLoss(eps::Real = 1e-10)\n\nLoss corresponding to the statistical assumption of Rayleigh data X with sacle given by the low-rank model tensor M\n\nDistribution: x_i sim operatornameRayleigh(theta_i)\nLink function: m_i = sqrtfracpi2theta_i\nLoss function: f(x m) = 2log(m + epsilon) + fracpi4(fracxm + epsilon)^2\nDomain: m in 0 infty)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.UserDefinedLoss","page":"Home","title":"GCPDecompositions.UserDefinedLoss","text":"UserDefinedLoss\n\nType for user-defined loss functions f(xm), where x is the data entry and m is the model entry.\n\nContains three fields:\n\nfunc::Function   : function that evaluates the loss function f(xm)\nderiv::Function  : function that evaluates the partial derivative partial_m f(xm) with respect to m\ndomain::Interval : Interval from IntervalSets.jl defining the domain for m\n\nThe constructor is UserDefinedLoss(func; deriv, domain). If not provided,\n\nderiv is automatically computed from func using forward-mode automatic differentiation\ndomain gets a default value of Interval(-Inf, +Inf)\n\n\n\n\n\n","category":"type"},{"location":"#GCPDecompositions.gcp","page":"Home","title":"GCPDecompositions.gcp","text":"gcp(X::Array, r, loss = LeastSquaresLoss();\n    constraints = default_constraints(loss),\n    algorithm = default_algorithm(X, r, loss, constraints)) -> CPD\n\nCompute an approximate rank-r CP decomposition of the tensor X with respect to the loss function loss and return a CPD object. The weights Î» are constrained to all be one and constraints is a Tuple of constraints on the factor matrices U = (U[1],...,U[N]). Conventional CP corresponds to the default LeastSquaresLoss() loss with no constraints (i.e., constraints = ()).\n\nIf the LossFunctions.jl package is also loaded, loss can also be a loss function from that package. Check GCPDecompositions.LossFunctionsExt.SupportedLosses to see what losses are supported.\n\nSee also: CPD, AbstractLoss.\n\n\n\n\n\n","category":"function"}]
}
